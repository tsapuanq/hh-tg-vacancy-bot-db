{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===\n",
    "load_dotenv()\n",
    "\n",
    "# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞ –∏ URL Gemini API ===\n",
    "GEMINI_API_KEY = os.getenv(\"GEM_API_TOKEN\")\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# === –í—ã–∑–æ–≤ Gemini API ===\n",
    "def call_gemini(prompt: str) -> str:\n",
    "    response = requests.post(\n",
    "        f\"{GEMINI_API_URL}?key={GEMINI_API_KEY}\",\n",
    "        headers=HEADERS,\n",
    "        json={\"contents\": [{\"parts\": [{\"text\": prompt}]}]},\n",
    "        timeout=30,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "\n",
    "# === –û—á–∏—Å—Ç–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ Gemini ===\n",
    "def clean_response(raw: str) -> dict:\n",
    "    cleaned = re.sub(r\"^```(?:json)?\\\\n?|```$\", \"\", raw.strip(), flags=re.IGNORECASE | re.MULTILINE).strip()\n",
    "    cleaned = cleaned.replace('\\u200b', '').replace('\\ufeff', '')\n",
    "    return json.loads(cleaned)\n",
    "\n",
    "# === –®–∞–±–ª–æ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤ ===\n",
    "SUMMARY_PROMPT_TEMPLATE = \"\"\"\n",
    "–†–∞–∑–±–µ–π —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞ —Ç—Ä–∏ –∫—Ä–∞—Ç–∫–∏—Ö –±–ª–æ–∫–∞:\n",
    "\n",
    "1. üìå *–û –∫–æ–º–ø–∞–Ω–∏–∏* ‚Äî –≤ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö.\n",
    "2. üßæ *–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏* ‚Äî —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã, –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É (–¥–æ 3‚Äì5 –ø—É–Ω–∫—Ç–æ–≤).\n",
    "3. üéØ *–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è* ‚Äî —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –∏ —É—Å–ª–æ–≤–∏—è, –∫—Ä–∞—Ç–∫–æ (–¥–æ 3‚Äì5 –ø—É–Ω–∫—Ç–æ–≤).\n",
    "\n",
    "üì¢ –ù–µ –ø–∏—à–∏ –≤–≤–æ–¥–Ω—ã—Ö —Ñ—Ä–∞–∑, –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞. –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ (‚Ä¢), –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ.\n",
    "üö´ –ï—Å–ª–∏ –¥–ª—è –∫–∞–∫–æ–≥–æ-–ª–∏–±–æ –±–ª–æ–∫–∞ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî —É–∫–∞–∂–∏ \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\".\n",
    "üîç –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∏—á–µ–≥–æ –Ω–æ–≤–æ–≥–æ ‚Äî —Ä–∞–±–æ—Ç–∞–π —Ç–æ–ª—å–∫–æ —Å —Ç–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤ –æ–ø–∏—Å–∞–Ω–∏–∏.\n",
    "\n",
    "–í–µ—Ä–Ω–∏ —á–∏—Å—Ç—ã–π JSON:\n",
    "```json\n",
    "{{\n",
    "  \"about_company\": \"...\",\n",
    "  \"responsibilities\": \"...\",\n",
    "  \"requirements\": \"...\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "FILTER_PROMPT = \"\"\"\n",
    "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏ –æ–ø–∏—Å–∞–Ω–∏—é.\n",
    "\n",
    "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π, –µ—Å–ª–∏ –æ–Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –æ–¥–Ω–æ–π –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö:\n",
    "- Data Scientist\n",
    "- Senior Data Scientist\n",
    "- Junior Data Scientist\n",
    "- Machine Learning Engineer\n",
    "- ML Engineer\n",
    "- Data Analyst\n",
    "- Senior Data Analyst\n",
    "- Data Engineer\n",
    "- Big Data Engineer\n",
    "- Data Architect\n",
    "- Business Intelligence Analyst\n",
    "- BI Analyst\n",
    "- Business Intelligence Developer\n",
    "- Statistician\n",
    "- Quantitative Analyst\n",
    "- NLP Engineer\n",
    "- Computer Vision Engineer\n",
    "- Deep Learning Engineer\n",
    "- Artificial Intelligence Engineer\n",
    "- AI Researcher\n",
    "- Data Researcher\n",
    "- Predictive Analytics Specialist\n",
    "- Data Science Manager\n",
    "- Analytics Consultant\n",
    "- Data Miner\n",
    "- Data Specialist\n",
    "- Data Modeler\n",
    "\n",
    "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: \"{title}\"\n",
    "–û–ø–∏—Å–∞–Ω–∏–µ: \"{description}\"\n",
    "\n",
    "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: yes –∏–ª–∏ no.\n",
    "\"\"\"\n",
    "\n",
    "# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è summary ===\n",
    "def generate_summary(description: str) -> dict:\n",
    "    if not description or len(description.strip()) < 50:\n",
    "        return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "    prompt = SUMMARY_PROMPT_TEMPLATE.format(description=description)\n",
    "    try:\n",
    "        raw = call_gemini(prompt)\n",
    "        return clean_response(raw)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary: {e}\")\n",
    "        return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "# === –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∞–∫–∞–Ω—Å–∏–π ===\n",
    "def filter_vacancy(title: str, description: str) -> bool:\n",
    "    prompt = FILTER_PROMPT.format(title=title, description=description)\n",
    "    try:\n",
    "        raw = call_gemini(prompt)\n",
    "        if not raw.strip():\n",
    "            print(f\"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary.\")\n",
    "            return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "        return clean_response(raw)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary: {e}\")\n",
    "        return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Data Engineer (Middle+) ‚Üí ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ\n",
      "üìã Data Scientist / ML Engineer ‚Üí ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ\n",
      "‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: Expecting ',' delimiter: line 2 column 25 (char 26)\n",
      "–û—Ç–≤–µ—Ç –æ—Ç Gemini:\n",
      "{\n",
      "  \"about_company\": \"–ê–û \"–ë–∞–Ω–∫–æ–≤—Å–∫–æ–µ –°–µ—Ä–≤–∏—Å–Ω–æ–µ –ë—é—Ä–æ –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –±–∞–Ω–∫–∞\" - –≤–µ–¥—É—â–∞—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è —Å–µ—Ä–≤–∏—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –ë–∞–Ω–∫–∞ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞. –†–∞–∑–≤–∏–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.\",\n",
      "  \"responsibilities\": \"‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö. ‚Ä¢ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. ‚Ä¢ –í–Ω–µ–¥—Ä–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –∏ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ. ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ ML-—Ä–µ—à–µ–Ω–∏–π (Python, Jupyter, scikit-learn, TensorFlow, PyTorch –∏ –¥—Ä.).\",\n",
      "  \"requirements\": \"‚Ä¢ –û–ø—ã—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö. ‚Ä¢ –ì–ª—É–±–æ–∫–∏–µ –∑–Ω–∞–Ω–∏—è Python –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è Data Science. ‚Ä¢ –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (TensorFlow, PyTorch) - –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ. ‚Ä¢ –ó–Ω–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö. ‚Ä¢ –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å SQL –∏ —Å–∏—Å—Ç–µ–º–∞–º–∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.\"\n",
      "}\n",
      "üìã Data Scientist / –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ AI-–±–æ—Ç–∞ ‚Üí ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ\n",
      "üìã Data Scientist ‚Üí ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ\n",
      "üìã Data Scientist (NLP) ‚Üí ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ\n",
      "üìã Data Scientist –î–∏—Ä–µ–∫—Ü–∏–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫—Ä–µ–¥–∏—Ç–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤ ‚Üí ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ\n",
      "üìã Senior Data Software Engineer (Big Data) ‚Üí ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ\n",
      "‚úÖ –ù–∞–π–¥–µ–Ω–æ 7 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===\n",
    "load_dotenv()\n",
    "\n",
    "# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞ –∏ URL Gemini API ===\n",
    "GEMINI_API_KEY = os.getenv(\"GEM_API_TOKEN\")\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# === –í—ã–∑–æ–≤ Gemini API ===\n",
    "def call_gemini(prompt: str) -> str:\n",
    "    response = requests.post(\n",
    "        f\"{GEMINI_API_URL}?key={GEMINI_API_KEY}\",\n",
    "        headers=HEADERS,\n",
    "        json={\"contents\": [{\"parts\": [{\"text\": prompt}]}]},\n",
    "        timeout=30,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "\n",
    "# === –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞ Gemini ===\n",
    "def safe_parse_json(raw: str) -> dict:\n",
    "    cleaned = re.sub(r\"^```(?:json)?\\n?|```$\", \"\", raw.strip(), flags=re.IGNORECASE | re.MULTILINE).strip()\n",
    "    cleaned = cleaned.replace('\\u200b', '').replace('\\ufeff', '')\n",
    "    cleaned = cleaned.replace('\\\\n', ' ').replace('\\\\', '')\n",
    "\n",
    "    if not (cleaned.startswith('{') and cleaned.endswith('}')):\n",
    "        print(f\"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON-–æ—Ç–≤–µ—Ç –æ—Ç Gemini (–Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∏ –Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ {{}}):\\n{cleaned}\")\n",
    "        return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(cleaned)\n",
    "\n",
    "        if not isinstance(parsed, dict):\n",
    "            print(f\"‚ùå –û–∂–∏–¥–∞–ª—Å—è –æ–±—ä–µ–∫—Ç dict, –Ω–æ –ø—Ä–∏—à–ª–æ: {type(parsed)} ‚Üí {parsed}\")\n",
    "            return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "        def process_field(value):\n",
    "            if isinstance(value, list):\n",
    "                return \" \".join(item.strip() for item in value if isinstance(item, str))\n",
    "            return str(value).strip()\n",
    "\n",
    "        about_company = process_field(parsed.get(\"about_company\", \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"))\n",
    "        responsibilities = process_field(parsed.get(\"responsibilities\", \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"))\n",
    "        requirements = process_field(parsed.get(\"requirements\", \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"))\n",
    "\n",
    "        return {\n",
    "            \"about_company\": about_company if about_company else \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\",\n",
    "            \"responsibilities\": responsibilities if responsibilities else \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\",\n",
    "            \"requirements\": requirements if requirements else \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\",\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}\\n–û—Ç–≤–µ—Ç –æ—Ç Gemini:\\n{cleaned}\")\n",
    "        return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "# === –®–∞–±–ª–æ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤ ===\n",
    "SUMMARY_PROMPT_TEMPLATE = \"\"\"\n",
    "–†–∞–∑–±–µ–π —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞ —Ç—Ä–∏ –∫—Ä–∞—Ç–∫–∏—Ö –±–ª–æ–∫–∞:\n",
    "\n",
    "1. üìå *–û –∫–æ–º–ø–∞–Ω–∏–∏* ‚Äî –≤ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö.\n",
    "2. üßæ *–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏* ‚Äî —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã, –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É (–¥–æ 3‚Äì5 –ø—É–Ω–∫—Ç–æ–≤).\n",
    "3. üéØ *–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è* ‚Äî —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –∏ —É—Å–ª–æ–≤–∏—è, –∫—Ä–∞—Ç–∫–æ (–¥–æ 3‚Äì5 –ø—É–Ω–∫—Ç–æ–≤).\n",
    "\n",
    "üì¢ –ù–µ –ø–∏—à–∏ –≤–≤–æ–¥–Ω—ã—Ö —Ñ—Ä–∞–∑, –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞. –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ (‚Ä¢), –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ.\n",
    "üö´ –ï—Å–ª–∏ –¥–ª—è –∫–∞–∫–æ–≥–æ-–ª–∏–±–æ –±–ª–æ–∫–∞ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî —É–∫–∞–∂–∏ \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\".\n",
    "üîç –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∏—á–µ–≥–æ –Ω–æ–≤–æ–≥–æ ‚Äî —Ä–∞–±–æ—Ç–∞–π —Ç–æ–ª—å–∫–æ —Å —Ç–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤ –æ–ø–∏—Å–∞–Ω–∏–∏.\n",
    "\n",
    "–í–µ—Ä–Ω–∏ —á–∏—Å—Ç—ã–π JSON:\n",
    "```json\n",
    "{{\n",
    "  \"about_company\": \"...\",\n",
    "  \"responsibilities\": \"...\",\n",
    "  \"requirements\": \"...\"\n",
    "}}\n",
    "```\n",
    "\n",
    "–û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏:\n",
    "{description}\n",
    "\"\"\"\n",
    "\n",
    "FILTER_PROMPT = \"\"\"\n",
    "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏ –æ–ø–∏—Å–∞–Ω–∏—é.\n",
    "\n",
    "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π, –µ—Å–ª–∏ –æ–Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –æ–¥–Ω–æ–π –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö:\n",
    "- Data Scientist\n",
    "- Senior Data Scientist\n",
    "- Junior Data Scientist\n",
    "- Machine Learning Engineer\n",
    "- ML Engineer\n",
    "- Data Analyst\n",
    "- Senior Data Analyst\n",
    "- Data Engineer\n",
    "- Big Data Engineer\n",
    "- Data Architect\n",
    "- Business Intelligence Analyst\n",
    "- BI Analyst\n",
    "- Business Intelligence Developer\n",
    "- Statistician\n",
    "- Quantitative Analyst\n",
    "- NLP Engineer\n",
    "- Computer Vision Engineer\n",
    "- Deep Learning Engineer\n",
    "- Artificial Intelligence Engineer\n",
    "- AI Researcher\n",
    "- Data Researcher\n",
    "- Predictive Analytics Specialist\n",
    "- Data Science Manager\n",
    "- Analytics Consultant\n",
    "- Data Miner\n",
    "- Data Specialist\n",
    "- Data Modeler\n",
    "\n",
    "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: \"{title}\"\n",
    "–û–ø–∏—Å–∞–Ω–∏–µ: \"{description}\"\n",
    "\n",
    "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: yes –∏–ª–∏ no.\n",
    "\"\"\"\n",
    "\n",
    "# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è summary ===\n",
    "def generate_summary(description: str) -> dict:\n",
    "    if not description or len(description.strip()) < 50:\n",
    "        return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "    prompt = SUMMARY_PROMPT_TEMPLATE.format(description=description)\n",
    "    try:\n",
    "        raw = call_gemini(prompt)\n",
    "        if not raw.strip():\n",
    "            print(f\"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary.\")\n",
    "            return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "        return safe_parse_json(raw)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary: {e}\")\n",
    "        return {\"about_company\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"responsibilities\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\", \"requirements\": \"–ù–µ —É–∫–∞–∑–∞–Ω–æ\"}\n",
    "\n",
    "# === –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∞–∫–∞–Ω—Å–∏–π ===\n",
    "def filter_vacancy(title: str, description: str) -> bool:\n",
    "    prompt = FILTER_PROMPT.format(title=title, description=description)\n",
    "    try:\n",
    "        raw = call_gemini(prompt)\n",
    "        if not raw.strip():\n",
    "            print(f\"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏.\")\n",
    "            return False\n",
    "        return raw.strip().lower() == \"yes\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}\")\n",
    "        return False\n",
    "\n",
    "# === –ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–æ–µ–≥–æ DataFrame ===\n",
    "df = pd.read_csv('C:/Users/User/hh_data_project/data/processed/vacancies_clean_2025-04-26.csv')\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ NaN –∑–Ω–∞—á–µ–Ω–∏–π –≤ –≤–∞–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö\n",
    "df = df.dropna(subset=['title', 'description'])\n",
    "\n",
    "# === –†–µ–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω ===\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    title = row.get('title', '')\n",
    "    description = row.get('description', '')\n",
    "\n",
    "    is_relevant = filter_vacancy(title, description)\n",
    "    print(f\"üìã {title} ‚Üí {'‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ' if is_relevant else '‚ùå –ù–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ'}\")\n",
    "\n",
    "    if is_relevant:\n",
    "        summary = generate_summary(description)\n",
    "        results.append({\n",
    "            'title': title,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
