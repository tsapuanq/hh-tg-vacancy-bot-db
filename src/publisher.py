import pandas as pd
import asyncio
import os
import random
import ast
from datetime import datetime
from telegram import Bot
from src.config import TELEGRAM_BOT_TOKEN, CHANNEL_USERNAME, get_today_processed_csv
from src.llm_summary import summarize_description_llm, filter_vacancy_llm

# â€”â€”â€” ĞŸÑƒÑ‚ÑŒ Ğ´Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… ÑÑÑ‹Ğ»Ğ¾Ğº â€”â€”â€”
SENT_LINKS_PATH = "data/sent_links.txt"

# â€”â€”â€” Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ€Ğ°Ğ½ĞµĞµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… ÑÑÑ‹Ğ»Ğ¾Ğº â€”â€”â€”
def load_sent_links(path: str = SENT_LINKS_PATH) -> set:
    if not os.path.exists(path):
        return set()
    with open(path, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

# â€”â€”â€” Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… ÑÑÑ‹Ğ»Ğ¾Ğº â€”â€”â€”
def append_sent_links(links: list, path: str = SENT_LINKS_PATH):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", encoding="utf-8") as f:
        for link in links:
            f.write(link + "\n")

# â€”â€”â€” Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ LLM-Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Markdown-Ğ±ÑƒĞ»Ğ»ĞµÑ‚Ñ‹ â€”â€”â€”
def _to_bullets(x) -> str:
    if isinstance(x, list):
        lines = x
    else:
        try:
            parsed = ast.literal_eval(x)
            lines = parsed if isinstance(parsed, list) else [x]
        except Exception:
            lines = [x]
    bullets = []
    for item in lines:
        s = str(item).strip().strip("'\"")
        if s:
            bullets.append(f"â€¢ {s}")
    return "\n".join(bullets) or "ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾"

# â€”â€”â€” Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸ Ğ´Ğ»Ñ Telegram â€”â€”â€”
def format_message(row: pd.Series, summary: dict) -> str:
    title = f"**{row.get('title','---')}**"
    pub_date = f"**{row.get('published_date','---')}**"
    resp = _to_bullets(summary.get('responsibilities', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾'))
    reqs = _to_bullets(summary.get('requirements', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾'))
    about = str(summary.get('about_company', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾')).strip().strip("'\"")

    return f"""
ğŸŒ *Ğ“Ğ¾Ñ€Ğ¾Ğ´:* {row.get('location', '---')}
ğŸ“… *Ğ”Ğ¾Ğ»Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ:* {title}
ğŸ’¼ *ĞšĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ:* {row.get('company', '---')}
ğŸ’° *Ğ—ĞŸ:* {row.get('salary_range') or row.get('salary') or '---'}

ğŸ“ *ĞĞ¿Ñ‹Ñ‚:* {row.get('experience', '---')}
ğŸ“‚ *Ğ¢Ğ¸Ğ¿ Ğ·Ğ°Ğ½ÑÑ‚Ğ¾ÑÑ‚Ğ¸:* {row.get('employment_type', '---')}
ğŸ“† *Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº:* {row.get('schedule', '---')}
ğŸ•’ *Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğµ Ñ‡Ğ°ÑÑ‹:* {row.get('working_hours', '---')}
ğŸ  *Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:* {row.get('work_format', '---')}
ğŸ“… *Ğ”Ğ°Ñ‚Ğ° Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸:* {pub_date}

ğŸ§¾ *ĞĞ±ÑĞ·Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸:*
{resp}

ğŸ¯ *Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:*
{reqs}

ğŸ¢ *Ğ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸:*
{about}

ğŸ” [ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ Ğ½Ğ° hh]({row['link']})
""".strip()

# â€”â€”â€” Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° CSV Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ ÑĞµĞ³Ğ¾Ğ´Ğ½ÑÑˆĞ½ĞµĞ¹ Ğ´Ğ°Ñ‚Ğµ â€”â€”â€”
from datetime import datetime

def load_today_rows():
    start_date = "2025-04-10"
    end_date = "2025-04-26"
    csv_path = get_today_processed_csv()
    if not os.path.exists(csv_path):
        print(f"âŒ CSV Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {csv_path}")
        return pd.DataFrame()
    try:
        df = pd.read_csv(csv_path)

        # Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¸Ğ¿ Ğ´Ğ°Ñ‚Ñ‹
        df["published_date_dt"] = pd.to_datetime(df["published_date_dt"], errors='coerce')

        if start_date and end_date:
            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñƒ
            return df[(df["published_date_dt"] >= start_date) & (df["published_date_dt"] <= end_date)]
        else:
            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ ÑĞµĞ³Ğ¾Ğ´Ğ½ÑÑˆĞ½ĞµĞ¹ Ğ´Ğ°Ñ‚Ğµ
            today_str = datetime.now().strftime("%Y-%m-%d")
            return df[df["published_date_dt"] == today_str]

    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ CSV: {e}")
        return pd.DataFrame()

# â€”â€”â€” ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ â€”â€”â€”
async def main():
    df = load_today_rows()
    if df.empty:
        print("â„¹ï¸ Ğ¡ĞµĞ³Ğ¾Ğ´Ğ½Ñ Ğ½ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹.")
        return

    sent_links = load_sent_links()
    df = df[~df["link"].isin(sent_links)]
    if df.empty:
        print("â„¹ï¸ Ğ’ÑĞµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸ ÑƒĞ¶Ğµ Ğ±Ñ‹Ğ»Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ñ€Ğ°Ğ½ĞµĞµ.")
        return

    # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Gemini LLM
    filtered = []
    for i, (_, row) in enumerate(df.iterrows(), 1):
        is_relevant = filter_vacancy_llm(row["title"], row["description"])
        print(f"[Gemini Filter] {row['title']} â†’ {'âœ…' if is_relevant else 'âŒ'}")
        if is_relevant:
            filtered.append(row)
        await asyncio.sleep(4.5)  # Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ 15 rpm

    if not filtered:
        print("âŒ ĞĞµÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ¿Ğ¾ÑĞ»Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸.")
        return

    df_filtered = pd.DataFrame(filtered)
    bot = Bot(token=TELEGRAM_BOT_TOKEN)

    for i, (_, row) in enumerate(df_filtered.iterrows(), 1):
        summary = summarize_description_llm(row["description"])
        text = format_message(row, summary)
        await bot.send_message(chat_id=CHANNEL_USERNAME, text=text, parse_mode="Markdown")
        print(f"âœ… [{i}/{len(df_filtered)}] Ğ’Ğ°ĞºĞ°Ğ½ÑĞ¸Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ°.")
        if i < len(df_filtered):
            delay = random.uniform(3, 10)
            print(f"â±ï¸ Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¿ĞµÑ€ĞµĞ´ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹: {delay:.2f} ÑĞµĞº.")
            await asyncio.sleep(delay)

    append_sent_links(df_filtered["link"].tolist())
    print(f"\nğŸ“¬ Ğ’ÑĞµĞ³Ğ¾ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: {len(df_filtered)} Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹.")

def run_publisher():
    return main()
