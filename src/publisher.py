# publisher.py
import asyncio
import random
import logging
import re
from telegram import Bot
from telegram.error import TelegramError
from src.config import (
    TELEGRAM_BOT_TOKEN,
    CHANNEL_USERNAME,
    TELEGRAM_DELAY_SECONDS,
    TELEGRAM_MAX_DELAY_SECONDS,
)
from src.llm_summary import summarize_description_llm, filter_vacancy_llm
from src.cleaning import clean_text_safe
from database import Database
from datetime import date, datetime 
import psycopg2.extras

def escape_markdown_v2(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã MarkdownV2 –≤ —Å—Ç—Ä–æ–∫–µ."""
    if not isinstance(text, str):
        text = str(text if text is not None else "")

    chars_to_escape = r"_*[]()~`>#+-=|{}.!"

    pattern = r"(" + "|".join(re.escape(char) for char in chars_to_escape) + r")"

    escaped_text = re.sub(pattern, r"\\\1", text)

    return escaped_text


def _to_bullets(x) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–ª–∏ —Å—Ç—Ä–æ–∫—É —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ Markdown."""
    if not x or (isinstance(x, str) and x.strip().lower() == "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"):
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

    if isinstance(x, list):
        lines = x
    else:
        lines = str(x).split("\n")

    bullets = []
    for item in lines:
        s = str(item).strip().strip("'\"")
        if s and s.lower() != "–Ω–µ —É–∫–∞–∑–∞–Ω–æ":
            escaped_item = escape_markdown_v2(s)
            bullets.append(f"‚Ä¢ {escaped_item}")

    return "\n".join(bullets) if bullets else "–ù–µ —É–∫–∞–∑–∞–Ω–æ"


def format_message(data: dict, summary: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ summary –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram –≤ MarkdownV2.
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π.
    """
    title = escape_markdown_v2(clean_text_safe(data.get("title", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")))
    company = escape_markdown_v2(clean_text_safe(data.get("company", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")))
    location = escape_markdown_v2(clean_text_safe(data.get("location", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")))

    salary_raw_val = data.get("salary_range") or data.get("salary")
    salary_raw_str = str(salary_raw_val) if salary_raw_val is not None else "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    salary_info = escape_markdown_v2(clean_text_safe(salary_raw_str))

    experience = escape_markdown_v2(
        clean_text_safe(data.get("experience", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))
    )
    employment_type = escape_markdown_v2(
        clean_text_safe(data.get("employment_type", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))
    )
    schedule = escape_markdown_v2(clean_text_safe(data.get("schedule", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")))
    working_hours = escape_markdown_v2(
        clean_text_safe(data.get("working_hours", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))
    )
    work_format = escape_markdown_v2(
        clean_text_safe(data.get("work_format", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))
    )

    pub_date_obj = data.get("published_at")
    pub_date_str_formatted = "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    if isinstance(pub_date_obj, date):
        try:
            pub_date_str_formatted = pub_date_obj.strftime("%d.%m.%Y")
        except Exception:
            pub_date_str_formatted = str(pub_date_obj)
    pub_date_str_formatted = escape_markdown_v2(pub_date_str_formatted)

    resp = _to_bullets(summary.get("responsibilities", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))
    reqs = _to_bullets(summary.get("requirements", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))

    about_raw = summary.get("about_company", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")
    about = escape_markdown_v2(clean_text_safe(about_raw))

    url = data.get("url", "#")
    link_text = escape_markdown_v2("–ü–æ–¥—Ä–æ–±–Ω–µ–µ –Ω–∞ hh")

    message_text = f"""\
üåê –ì–æ—Ä–æ–¥: {location}
üìÖ –î–æ–ª–∂–Ω–æ—Å—Ç—å: **{title}**
üíº –ö–æ–º–ø–∞–Ω–∏—è: {company}
üí∞ –ó–ü: {salary_info}

üéì –û–ø—ã—Ç: {experience}
üìÇ –¢–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏: {employment_type}
üìÜ –ì—Ä–∞—Ñ–∏–∫: {schedule}
üïí –†–∞–±–æ—á–∏–µ —á–∞—Å—ã: {working_hours}
üè† –§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã: {work_format}
üìÖ –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {pub_date_str_formatted}

üßæ –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:
{resp}

üéØ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
{reqs}

üè¢ –û –∫–æ–º–ø–∞–Ω–∏–∏:
{about}

üîé [{link_text}]({url})
"""

    return message_text


async def main(db: Database):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è, –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram.
    """
    conn = None
    cursor = None

    try:
        conn = db.get_connection()
        cursor = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)

        logging.info("üïµÔ∏è‚Äç‚ôÇÔ∏è –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π...")
        cursor.execute(
            """
            SELECT id, title, description
            FROM vacancies
            WHERE is_relevant IS NULL AND published_at = CURRENT_DATE
            """
        )
        rows_to_filter = cursor.fetchall()
        logging.info(
            f"üìä –ù–∞–π–¥–µ–Ω–æ {len(rows_to_filter)} –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏."
        )

        for idx, row in enumerate(rows_to_filter, 1):
            vacancy_id = row["id"]
            title = row["title"]
            description = row["description"]

            logging.info(
                f"[Gemini Filter] [{idx}/{len(rows_to_filter)}] –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è: {title}"
            )
            try:
                is_relevant = filter_vacancy_llm(title, description)
                logging.info(
                    f"[Gemini Filter] {title} ‚Üí {'‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ' if is_relevant else '‚ùå –ù–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ'}"
                )

                cursor.execute(
                    "UPDATE vacancies SET is_relevant = %s WHERE id = %s",
                    (
                        is_relevant,
                        vacancy_id,
                    ),
                )

                await asyncio.sleep(4.5)  

            except Exception as e:
                logging.error(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_id} ('{title}'): {e}",
                    exc_info=True,
                )

        conn.commit()

        logging.info("üìù –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—É–º–º–∞—Ä–∏ –¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π...")
        cursor.execute(
            """
            SELECT id, description
            FROM vacancies
            -- –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç –ø–æ–ª–Ω–æ–≥–æ —Å—É–º–º–∞—Ä–∏
            WHERE is_relevant = TRUE
              AND (summary_duties IS NULL OR summary_requirements IS NULL OR summary_company IS NULL)
              AND published_at = CURRENT_DATE
            """
        )
        rows_to_summarize = cursor.fetchall()
        logging.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(rows_to_summarize)} –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.")

        for idx, row in enumerate(rows_to_summarize, 1):
            vacancy_id = row["id"]
            description = row["description"]

            logging.info(
                f"[Gemini Summary] [{idx}/{len(rows_to_summarize)}] –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—É–º–º–∞—Ä–∏ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_id}..."
            )
            try:
                summary = summarize_description_llm(
                    description
                ) 
 
                responsibilities_list = summary.get("responsibilities", ["–ù–µ —É–∫–∞–∑–∞–Ω–æ"])
                requirements_list = summary.get("requirements", ["–ù–µ —É–∫–∞–∑–∞–Ω–æ"])
                about_company_string = summary.get(
                    "about_company", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
                )  

                responsibilities_string = "\n".join(
                    map(str, responsibilities_list)
                )  
                requirements_string = "\n".join(map(str, requirements_list))

                cursor.execute(
                    """
                    UPDATE vacancies
                    SET summary_duties = %s, summary_requirements = %s, summary_company = %s
                    WHERE id = %s
                    """,
                    (
                        responsibilities_string,  
                        requirements_string,  
                        about_company_string,
                        vacancy_id,
                    ),
                )
                await asyncio.sleep(4.5)

            except Exception as e:
                logging.error(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_id}: {e}",
                    exc_info=True,
                )

        conn.commit()

        logging.info("üì¨ –®–∞–≥ 3: –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram...")
        cursor.execute(
            """
            SELECT id, title, company, location, salary, salary_range, experience, employment_type, schedule,
                   working_hours, work_format, published_at, summary_duties, summary_requirements,
                   summary_company, url
            FROM vacancies
            WHERE is_relevant = TRUE
              AND published_at = CURRENT_DATE -- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ–≥–æ–¥–Ω—è –∏–ª–∏ –ø–æ–∑–∂–µ
              AND sent_to_telegram = FALSE -- –ï—â–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
              AND summary_duties IS NOT NULL -- –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
              AND summary_requirements IS NOT NULL
              AND summary_company IS NOT NULL
              AND summary_company IS NOT NULL
            """
        )
        rows_to_publish = cursor.fetchall()

        if not rows_to_publish:
            logging.info("‚ÑπÔ∏è –°–µ–≥–æ–¥–Ω—è –Ω–µ—Ç –Ω–æ–≤—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.")
        else:
            logging.info(
                f"üìä –ù–∞–π–¥–µ–Ω–æ {len(rows_to_publish)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏ –Ω–µ–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏."
            )

            if not TELEGRAM_BOT_TOKEN or not CHANNEL_USERNAME:
                logging.error(
                    "‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –∏–ª–∏ –∏–º—è –∫–∞–Ω–∞–ª–∞ Telegram –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É."
                )
            else:
                bot = Bot(token=TELEGRAM_BOT_TOKEN)

                for idx, row in enumerate(rows_to_publish, 1):
                    data = dict(row)

                    summary = {
                        "responsibilities": data.get("summary_duties"),
                        "requirements": data.get("summary_requirements"),
                        "about_company": data.get("summary_company"),
                    }
                    text = format_message(data, summary)

                    try:
                        await bot.send_message(
                            chat_id=CHANNEL_USERNAME,
                            text=text,
                            parse_mode="MarkdownV2",
                        )
                        logging.info(
                            f"‚úÖ [{idx}/{len(rows_to_publish)}] –í–∞–∫–∞–Ω—Å–∏—è {data.get('id', 'N/A')} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ Telegram."
                        )

                        cursor.execute(
                            "UPDATE vacancies SET sent_to_telegram = TRUE WHERE id = %s",
                            (data["id"],),
                        )
                        conn.commit()  

                    except TelegramError as e:
                        logging.error(
                            f"‚ùå –û—à–∏–±–∫–∞ Telegram API –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {data.get('id', 'N/A')} ('{data.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}'): {e}"
                        )
                        continue  

                    except Exception as e:
                        logging.error(
                            f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {data.get('id', 'N/A')} ('{data.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}'): {e}",
                            exc_info=True,
                        )
                        continue  

                    if idx < len(rows_to_publish):
                        delay = random.uniform(
                            TELEGRAM_DELAY_SECONDS, TELEGRAM_MAX_DELAY_SECONDS
                        )
                        logging.info(
                            f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –æ—Ç–ø—Ä–∞–≤–∫–æ–π: {delay:.2f} —Å–µ–∫."
                        )
                        await asyncio.sleep(delay)

        logging.info("üßπ –ó–∞–ø—É—Å–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π...")
        try:
            cursor.execute("DELETE FROM vacancies WHERE is_relevant = FALSE;")
            deleted_irrelevant_count = cursor.rowcount
            if deleted_irrelevant_count > 0:
                logging.info(
                    f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {deleted_irrelevant_count} –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π."
                )
            else:
                logging.info("‚úÖ –ù–µ—Ç –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")

            cursor.execute(
                "DELETE FROM vacancies WHERE sent_to_telegram = FALSE AND processed_at < CURRENT_DATE;"
            )
            deleted_old_not_sent_count = cursor.rowcount
            if deleted_old_not_sent_count > 0:
                logging.info(
                    f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {deleted_old_not_sent_count} —Å—Ç–∞—Ä—ã—Ö –Ω–µ–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π (–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –¥–æ —Å–µ–≥–æ–¥–Ω—è)."
                )
            else:
                logging.info("‚úÖ –ù–µ—Ç —Å—Ç–∞—Ä—ã—Ö –Ω–µ–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")

            conn.commit()  

        except Exception as e:
            logging.error(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π: {e}",
                exc_info=True,
            )
            if conn:
                conn.rollback()  

    except Exception as e:
        logging.error(
            f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {e}", exc_info=True
        )

    finally:
        if cursor:
            cursor.close()
        if conn:
            db.return_connection(conn)

def run_publisher(db):
    import psycopg2.extras

    return asyncio.run(main(db))
